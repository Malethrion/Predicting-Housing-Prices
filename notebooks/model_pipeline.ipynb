{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('data/train.csv')\n",
    "\n",
    "# Display the first few rows to check\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = df.drop('target_column', axis=1)  # Replace 'target_column' with the actual column name\n",
    "y = df['target_column']\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check shapes of resulting data\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "linear_regression = LinearRegression()\n",
    "random_forest = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "xgboost = xgb.XGBRegressor(n_estimators=100, random_state=42)\n",
    "lightgbm = lgb.LGBMRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the models on the training data\n",
    "linear_regression.fit(X_train, y_train)\n",
    "random_forest.fit(X_train, y_train)\n",
    "xgboost.fit(X_train, y_train)\n",
    "lightgbm.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target on the test set\n",
    "y_pred_lr = linear_regression.predict(X_test)\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "y_pred_xgb = xgboost.predict(X_test)\n",
    "y_pred_lgb = lightgbm.predict(X_test)\n",
    "\n",
    "# Calculate the performance of each model\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "mae_lgb = mean_absolute_error(y_test, y_pred_lgb)\n",
    "\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Linear Regression MAE: {mae_lr}, R^2: {r2_lr}\")\n",
    "print(f\"Random Forest MAE: {mae_rf}, R^2: {r2_rf}\")\n",
    "print(f\"XGBoost MAE: {mae_xgb}, R^2: {r2_xgb}\")\n",
    "print(f\"LightGBM MAE: {mae_lgb}, R^2: {r2_lgb}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
