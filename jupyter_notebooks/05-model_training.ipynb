{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "This notebook trains a machine learning model to predict house prices using the processed dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Processed Dataset\n",
    "We load the processed dataset containing cleaned and engineered features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded processed dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.730865</td>\n",
       "      <td>0.073375</td>\n",
       "      <td>-0.229372</td>\n",
       "      <td>-0.207142</td>\n",
       "      <td>0.651479</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>1.050994</td>\n",
       "      <td>0.878668</td>\n",
       "      <td>0.511418</td>\n",
       "      <td>0.575425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.728492</td>\n",
       "      <td>-0.872563</td>\n",
       "      <td>0.451936</td>\n",
       "      <td>-0.091886</td>\n",
       "      <td>-0.071836</td>\n",
       "      <td>2.179628</td>\n",
       "      <td>0.156734</td>\n",
       "      <td>-0.429577</td>\n",
       "      <td>-0.574410</td>\n",
       "      <td>1.171992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.726120</td>\n",
       "      <td>0.073375</td>\n",
       "      <td>-0.093110</td>\n",
       "      <td>0.073480</td>\n",
       "      <td>0.651479</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>0.984752</td>\n",
       "      <td>0.830215</td>\n",
       "      <td>0.323060</td>\n",
       "      <td>0.092907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.723747</td>\n",
       "      <td>0.309859</td>\n",
       "      <td>-0.456474</td>\n",
       "      <td>-0.096897</td>\n",
       "      <td>0.651479</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>-1.863632</td>\n",
       "      <td>-0.720298</td>\n",
       "      <td>-0.574410</td>\n",
       "      <td>-0.499274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.721374</td>\n",
       "      <td>0.073375</td>\n",
       "      <td>0.633618</td>\n",
       "      <td>0.375148</td>\n",
       "      <td>1.374795</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>0.951632</td>\n",
       "      <td>0.733308</td>\n",
       "      <td>1.364570</td>\n",
       "      <td>0.463568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 289 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id  MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  \\\n",
       "0 -1.730865    0.073375    -0.229372 -0.207142     0.651479    -0.517200   \n",
       "1 -1.728492   -0.872563     0.451936 -0.091886    -0.071836     2.179628   \n",
       "2 -1.726120    0.073375    -0.093110  0.073480     0.651479    -0.517200   \n",
       "3 -1.723747    0.309859    -0.456474 -0.096897     0.651479    -0.517200   \n",
       "4 -1.721374    0.073375     0.633618  0.375148     1.374795    -0.517200   \n",
       "\n",
       "   YearBuilt  YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  SaleType_ConLw  \\\n",
       "0   1.050994      0.878668    0.511418    0.575425  ...             0.0   \n",
       "1   0.156734     -0.429577   -0.574410    1.171992  ...             0.0   \n",
       "2   0.984752      0.830215    0.323060    0.092907  ...             0.0   \n",
       "3  -1.863632     -0.720298   -0.574410   -0.499274  ...             0.0   \n",
       "4   0.951632      0.733308    1.364570    0.463568  ...             0.0   \n",
       "\n",
       "   SaleType_New  SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  \\\n",
       "0           0.0           0.0          1.0                    0.0   \n",
       "1           0.0           0.0          1.0                    0.0   \n",
       "2           0.0           0.0          1.0                    0.0   \n",
       "3           0.0           0.0          1.0                    1.0   \n",
       "4           0.0           0.0          1.0                    0.0   \n",
       "\n",
       "   SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n",
       "0                    0.0                   0.0                   0.0   \n",
       "1                    0.0                   0.0                   0.0   \n",
       "2                    0.0                   0.0                   0.0   \n",
       "3                    0.0                   0.0                   0.0   \n",
       "4                    0.0                   0.0                   0.0   \n",
       "\n",
       "   SaleCondition_Normal  SaleCondition_Partial  \n",
       "0                   1.0                    0.0  \n",
       "1                   1.0                    0.0  \n",
       "2                   1.0                    0.0  \n",
       "3                   0.0                    0.0  \n",
       "4                   1.0                    0.0  \n",
       "\n",
       "[5 rows x 289 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the processed dataset\n",
    "data = pd.read_csv(\"../data/processed_train.csv\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"Loaded processed dataset:\")\n",
    "data.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Features and Target Variable\n",
    "We separate the dataset into features (`X`) and the target variable (`y`), applying log transformation to stabilize predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split into training and testing sets successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define target variable\n",
    "target = \"SalePrice\"\n",
    "\n",
    "# Ensure SalePrice has only positive values before log transformation\n",
    "data = data[data[target] > 0]  # Remove rows with zero or negative SalePrice\n",
    "\n",
    "# Apply log transformation\n",
    "data[target] = np.log(data[target])  # Convert target to log-scale\n",
    "\n",
    "# Drop any remaining NaN values from features and target\n",
    "data = data.dropna()\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data.drop(columns=[target])\n",
    "y = data[target]\n",
    "\n",
    "# Split dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Dataset split into training and testing sets successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Feature Scaling\n",
    "We scale the feature set using `StandardScaler` to improve model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data and transform both train and test sets\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "We use a `RandomForestRegressor` to train the model on the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training completed.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model using scaled features\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Model training completed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "We use evaluation metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared Score to assess model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:\n",
      "Mean Absolute Error (MAE): 0.3099880135764689\n",
      "Mean Squared Error (MSE): 0.21456673032475418\n",
      "R-squared Score: 0.6921372522756812\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Reverse log transformation for price predictions\n",
    "y_pred_actual = np.exp(y_pred)\n",
    "y_test_actual = np.exp(y_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "mae = mean_absolute_error(y_test_actual, y_pred_actual)\n",
    "mse = mean_squared_error(y_test_actual, y_pred_actual)\n",
    "r2 = r2_score(y_test_actual, y_pred_actual)\n",
    "\n",
    "# Display evaluation results\n",
    "print(f\"Model Performance:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared Score: {r2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Trained Model\n",
    "The trained model, feature names, and scaler are saved as `.pkl` files for future use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model, feature names, and scaler saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Ensure the models directory exists\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "# Save the trained model\n",
    "with open(\"../models/trained_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Save feature names\n",
    "with open(\"../models/feature_names.pkl\", \"wb\") as f:\n",
    "    pickle.dump(X_train.columns.tolist(), f)\n",
    "\n",
    "# Save the scaler\n",
    "with open(\"../models/scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"Trained model, feature names, and scaler saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- Loaded the processed dataset.\n",
    "- Applied log transformation to target variable.\n",
    "- Scaled feature set using `StandardScaler`.\n",
    "- Trained a `RandomForestRegressor` model on scaled data.\n",
    "- Evaluated model performance using MAE, MSE, and RÂ² score.\n",
    "- Saved the trained model, feature names, and scaler.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
